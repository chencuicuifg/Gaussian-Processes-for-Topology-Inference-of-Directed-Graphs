{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bfc565-b38d-448c-a868-bc3d501ec1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import torch\n",
    "import gpytorch \n",
    "import math\n",
    "def Inference(Xtrain,Ytrain,likelihoods,models, training_iter=None,learning_rate= None,ifPrint = True,numPrint = 20):\n",
    "    N = len(likelihoods) # number of dimension\n",
    "    W = torch.zeros(N,N) # create the weighted adjacency matrix W\n",
    "    \n",
    "    if training_iter is None:\n",
    "        training_iter = 200 # defauld training iter\n",
    "    if learning_rate is None:\n",
    "        learning_rate = 0.005 # default learning rate\n",
    "\n",
    "    \n",
    "    for n in range(N):\n",
    "        print(\"processing for nodes\" + str(n+1))\n",
    "        \n",
    "        # target variable for each node\n",
    "        ytrain = Ytrain[:,n]\n",
    "        \n",
    "        # model for each nodes\n",
    "        llh = likelihoods[n]\n",
    "        model = models[n]  \n",
    "        \n",
    "        # in training mode\n",
    "        model.train()\n",
    "        llh.train()\n",
    "\n",
    "        # optimizer\n",
    "        optimizer = torch.optim.LBFGS(model.parameters(),lr = learning_rate)\n",
    "        \n",
    "        #marginal likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(llh,model)\n",
    "    \n",
    "        for i in range(training_iter):\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                output = model(Xtrain)\n",
    "                loss = -mll(output, ytrain)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            optimizer.step(closure)\n",
    "            loss = optimizer.step(closure)\n",
    "            if ifPrint is True:\n",
    "                if (i+1) % numPrint == 0:\n",
    "                    log_message = 'Iter %d/%d loss: %.3f' % (i + 1, training_iter, loss.item())\n",
    "                    lengthscale_values = model.covar_module.base_kernel.lengthscale[0]   \n",
    "                    for idx, lengthscale in enumerate(lengthscale_values):\n",
    "                        log_message += ' W%d: %.8f' % (idx + 1, math.log(1 / lengthscale.item()))\n",
    "                    noise_value = model.likelihood.noise.item()\n",
    "                    log_message += ' noise: %.8f' % noise_value\n",
    "                    print(log_message)\n",
    "        W[n,:] = torch.log(1/model.covar_module.base_kernel.lengthscale[0])\n",
    "    return W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
